{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17db494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9702127659574468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       448\n",
      "           1       0.95      0.97      0.96       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.97      0.97      0.97       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Class Label(GDM /Non GDM)'])\n",
    "y = data['Class Label(GDM /Non GDM)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a1a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9631205673758865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       448\n",
      "           1       0.96      0.94      0.95       257\n",
      "\n",
      "    accuracy                           0.96       705\n",
      "   macro avg       0.96      0.96      0.96       705\n",
      "weighted avg       0.96      0.96      0.96       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train the Decision Tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4865fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730496453900709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       448\n",
      "           1       0.96      0.96      0.96       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.97      0.97      0.97       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df7c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9673758865248226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       448\n",
      "           1       0.95      0.96      0.96       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.96      0.97      0.96       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15578296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9673758865248226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       448\n",
      "           1       0.94      0.98      0.96       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.96      0.97      0.97       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the SVM model\n",
    "model = SVC()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a825224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9744680851063829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       448\n",
      "           1       0.95      0.98      0.97       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.97      0.98      0.97       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train the kNN model\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea20b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9517730496453901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       448\n",
      "           1       0.93      0.94      0.93       257\n",
      "\n",
      "    accuracy                           0.95       705\n",
      "   macro avg       0.95      0.95      0.95       705\n",
      "weighted avg       0.95      0.95      0.95       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517ae4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9673758865248226\n",
      "ROC-AUC Score: 0.9835498888271262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       448\n",
      "           1       0.95      0.96      0.96       257\n",
      "\n",
      "    accuracy                           0.97       705\n",
      "   macro avg       0.96      0.97      0.96       705\n",
      "weighted avg       0.97      0.97      0.97       705\n",
      "\n",
      "Probability predictions: [4.74407243e-02 9.99982076e-01 9.75301991e-01 3.26582419e-03\n",
      " 1.24604008e-01 8.31663885e-01 9.99987233e-01 3.43120145e-03\n",
      " 1.95608412e-02 3.23700197e-05]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Drop the \"Case Number\" column\n",
    "data.drop(columns=['Case Number'], inplace=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Class Label(GDM /Non GDM)'])\n",
    "y = data['Class Label(GDM /Non GDM)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Make probability predictions on the test set\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability of the positive class (GDM)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print probability predictions for the first few instances\n",
    "print(\"Probability predictions:\", y_prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7a7f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'new_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edc57f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.06561903926867957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Drop the \"Case Number\" column\n",
    "data.drop(columns=['Case Number'], inplace=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Class Label(GDM /Non GDM)'])\n",
    "y = data['Class Label(GDM /Non GDM)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "    # Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931a3c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'linear_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "179642b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# random forest used for regression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Drop the \"Case Number\" column\n",
    "data.drop(columns=['Case Number'], inplace=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Class Label(GDM /Non GDM)'])\n",
    "y = data['Class Label(GDM /Non GDM)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Train the Random Forest Classifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_path = 'random_classification_model.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63c4ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the file path to save the model\n",
    "model_path = 'random_forest_regression_model.pkl'\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "010ed5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.6616645613145555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Drop the \"Case Number\" column\n",
    "data.drop(columns=['Case Number'], inplace=True)\n",
    "\n",
    "# Standardize feature names (lowercase and replace spaces with underscores)\n",
    "data.columns = [col.lower().replace(' ', '_') for col in data.columns]\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['class_label(gdm_/non_gdm)'])\n",
    "y = data['class_label(gdm_/non_gdm)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a .pkl file\n",
    "joblib.dump(model, 'linear_regression_model.pkl')\n",
    "joblib.dump(imputer, 'imputer.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Load the model and test it\n",
    "model = joblib.load('linear_regression_model.pkl')\n",
    "imputer = joblib.load('imputer.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c43dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9835498888271262\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('/Users/harishgattamaneni/Downloads/Gestational Diabetic Dat Set.xlsx')\n",
    "\n",
    "# Drop the \"Case Number\" column\n",
    "data.drop(columns=['Case Number'], inplace=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Class Label(GDM /Non GDM)'])\n",
    "y = data['Class Label(GDM /Non GDM)']\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c1c9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951a6e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming your trained kNN model is stored in the variable 'model'\n",
    "joblib.dump(model, 'knn_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f39d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (fsevents)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 991, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 113, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:55337')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harishgattamaneni/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained kNN model\n",
    "model = joblib.load('knn_model.pkl')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json  # Assuming input data is sent as JSON\n",
    "    # Perform any necessary preprocessing on the input data\n",
    "    # Make predictions using the loaded kNN model\n",
    "    prediction = model.predict(data)\n",
    "    # Prepare response\n",
    "    response = {'prediction': prediction}\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0821c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
